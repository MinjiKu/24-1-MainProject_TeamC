{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주의 : my SQL에서 OD데이터 파일 생성 이후 사용!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정류소 정보 불러오기\n",
    "info = pd.read_excel('/Users/taejin/Desktop/데분 학회/급행버스/서울시버스노선별정류소정보.xlsx')\n",
    "\n",
    "# 불필요한 컬럼 및 중복 제거\n",
    "# info.drop(['NODE_ID'], axis=1, inplace=True)\n",
    "info.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 정류장명 & 좌표 매핑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O/D data temp 파일 불러옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일 경로 지정\n",
    "directory_path = '/Users/taejin/Desktop/데분 학회/급행버스/'\n",
    "\n",
    "# 파일 리스트에서 CSV 파일만 필터링\n",
    "csv_files = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "\n",
    "# 데이터프레임 딕셔너리 생성\n",
    "dataframes = {}\n",
    "\n",
    "# 각 CSV 파일을 데이터프레임으로 읽어와서 딕셔너리에 저장\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(directory_path, csv_file)\n",
    "    df_name = os.path.splitext(csv_file)[0]  # 파일명에서 확장자 제거하여 데이터프레임 이름으로 사용\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['노선명'] = df['노선명'].astype(str)\n",
    "    df.rename(columns={'avg(승객수)' : '승객수'}, inplace=True)\n",
    "    dataframes[df_name] = df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정류장명 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 노선명 ARS_ID 딕셔너리\n",
    "info_dict = info[['ARS_ID', '정류소명']].set_index('ARS_ID')['정류소명'].to_dict()\n",
    "\n",
    "# 정류장명 매핑\n",
    "for df_name in list(dataframes.keys()):\n",
    "    df = dataframes[df_name]\n",
    "    df['승차정류장'] = df['승차_정류장ARS'].map(info_dict)\n",
    "    df['하차정류장'] = df['하차_정류장ARS'].map(info_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "좌표 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARS_ID, 좌표 딕셔너리\n",
    "info_gpsX = info[['ARS_ID', 'X좌표']].set_index('ARS_ID')['X좌표'].to_dict()\n",
    "info_gpsY = info[['ARS_ID', 'Y좌표']].set_index('ARS_ID')['Y좌표'].to_dict()\n",
    "\n",
    "# 좌표 매핑\n",
    "for df_name in list(dataframes.keys()):\n",
    "    df = dataframes[df_name]\n",
    "    df['승차정류장_X좌표'] = df['승차_정류장ARS'].map(info_gpsX)\n",
    "    df['승차정류장_Y좌표'] = df['승차_정류장ARS'].map(info_gpsY)\n",
    "    df['하차정류장_X좌표'] = df['하차_정류장ARS'].map(info_gpsX)\n",
    "    df['하차정류장_Y좌표'] = df['하차_정류장ARS'].map(info_gpsY)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "노선명 route id 매핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# route_id 노선명 딕셔너리\n",
    "routeID_dict = info[['노선명', 'ROUTE_ID']].set_index('노선명')['ROUTE_ID'].to_dict()\n",
    "\n",
    "# route id 매핑\n",
    "for df_name in list(dataframes.keys()):\n",
    "    df = dataframes[df_name]\n",
    "    df['ROUTE_ID'] = df['노선명'].map(routeID_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 내보내기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "od_temp2 데이터 내보냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Name: od_weekend_temp\n",
      "DataFrame Name: od_weekday_temp\n"
     ]
    }
   ],
   "source": [
    "# 각 데이터프레임 출력 (필요 시)\n",
    "for df_name, df in dataframes.items():\n",
    "    print(f\"DataFrame Name: {df_name}\")\n",
    "    # print(df.head())  # 첫 5개 행 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i , data in enumerate(list(dataframes.values())):\n",
    "    # csv파일로 저장\n",
    "    dataframes[list(dataframes.keys())[i]].to_csv(f'/Users/taejin/Desktop/데분 학회/급행버스/{list(dataframes.keys())[i]}2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i , data in enumerate(list(dataframes.values())):\n",
    "\n",
    "#     #불필요한 컬럼 제거\n",
    "#     # data.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "#     # 승차 정류장 좌표\n",
    "#     merged_df = pd.merge(data, info, left_on=['노선명','승차_정류장ARS', '승차_정류장명'], right_on=['노선명', 'ARS_ID', '정류소명'], how='left')\n",
    "#     merged_df.rename(columns={'X좌표' : '승차정류장_X좌표', 'Y좌표' : '승차정류장_Y좌표'}, inplace=True)\n",
    "\n",
    "#     #불필요한 컬럼 제거\n",
    "#     merged_df.drop(['정류소명', 'ARS_ID'], axis=1, inplace=True)\n",
    "\n",
    "#     #하차 정류장 좌표\n",
    "#     merged_df = pd.merge(merged_df, info, left_on=['노선명','하차_정류장ARS', '하차_정류장명'], right_on=['노선명', 'ARS_ID', '정류소명'], how='left')\n",
    "#     merged_df.rename(columns={'X좌표' : '하차정류장_X좌표', 'Y좌표' : '하차정류장_Y좌표'}, inplace=True)\n",
    "\n",
    "#     #불필요한 컬럼 제거\n",
    "#     merged_df.drop(['정류소명', 'ARS_ID'], axis=1, inplace=True)\n",
    "\n",
    "#     # 데이터프레임 딕셔너리에 저장\n",
    "#     dataframes[list(dataframes.keys())[i]] = merged_df\n",
    "\n",
    "#     # csv파일로 저장\n",
    "#     dataframes[list(dataframes.keys())[i]].to_csv(f'/Users/taejin/Desktop/데분 학회/급행버스/{list(dataframes.keys())[i]}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.승하차 정류장 순번 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name in list(dataframes.keys()):\n",
    "    df = dataframes[df_name]\n",
    "    \n",
    "    # 승하차 정류장 순번 추가\n",
    "    df['승차_정류장순번'] = ''\n",
    "    df['하차_정류장순번'] = ''\n",
    "    \n",
    "    # 승차 하차 순번 저장\n",
    "    for route_name in station_by_route_dict.keys():\n",
    "        api_df = station_by_route_dict[route_name]\n",
    "        # api_df = api_df[['seq', 'arsId']].fillna(-1).astype(int)\n",
    "        sequence_dict = api_df[['arsId', 'seq']].fillna(-1).astype(int).set_index('arsId')['seq'].to_dict()\n",
    "        \n",
    "        # '승차_정류장순번' 열 추가\n",
    "        df.loc[df['노선명'] == route_name, '승차_정류장순번'] = df.loc[df['노선명'] == route_name, '승차_정류장ARS'].map(sequence_dict)\n",
    "        # '하차_정류장순번' 열 추가\n",
    "        df.loc[df['노선명'] == route_name, '하차_정류장순번'] = df.loc[df['노선명'] == route_name, '하차_정류장ARS'].map(sequence_dict)\n",
    "        # 방향 열 추가\n",
    "    dataframes[df_name] = df    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 방향 및 속도 정보 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sql 구문에서 api_station_by_route와 od_week_temp2 데이터 병합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 상위 20개 노선 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[143, 151, 1164, 2211, 3315, 5513, 5515, 5617, 5621, 6628, 7016, 7612, 7734]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일 경로 지정\n",
    "directory_path = '/Users/taejin/Desktop/데분 학회/급행버스/'\n",
    "\n",
    "# 파일 리스트에서 CSV 파일만 필터링\n",
    "csv_files = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "\n",
    "# 데이터프레임 딕셔너리 생성\n",
    "dataframes = {}\n",
    "\n",
    "# 각 CSV 파일을 데이터프레임으로 읽어와서 딕셔너리에 저장\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(directory_path, csv_file)\n",
    "    df_name = os.path.splitext(csv_file)[0]  # 파일명에서 확장자 제거하여 데이터프레임 이름으로 사용\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['노선명'] = df['노선명'].astype(str)\n",
    "    df.rename(columns={'avg(승객수)' : '승객수'}, inplace=True)\n",
    "    dataframes[df_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['703', '8551', '8112', '1140'], dtype=object)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes['od_weekday'][dataframes['od_weekday']['방향'].isna()]['노선명'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_weekday = dataframes['od_weekday']\n",
    "top_20_weekend = dataframes['od_weekend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "route_list = ['143', '151', '1164', '2211', '3315', '5513', '5515', '5617', '5621', '6628', '7016', '7612', '7734']\n",
    "\n",
    "top_20_weekday = top_20_weekday[top_20_weekday['노선명'].isin(route_list)]\n",
    "top_20_weekend = top_20_weekend[top_20_weekend['노선명'].isin(route_list)]\n",
    "\n",
    "top_20_weekday.to_csv('/Users/taejin/Desktop/데분 학회/급행버스/top_20_od_weekday.csv')\n",
    "top_20_weekend.to_csv('/Users/taejin/Desktop/데분 학회/급행버스/top_20_od_weekend.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
